from transformers import BlenderbotTokenizer, BlenderbotForConditionalGenerationmodel_name = "facebook/blenderbot-400M-distill"tokenizer = BlenderbotTokenizer.from_pretrained(model_name)model = BlenderbotForConditionalGeneration.from_pretrained(model_name)# Conversation history (last few messages)conversation_history = []while True:    user_input = input("> ")    # Append user input to the history    conversation_history.append(f"User: {user_input}")    # Prepare the dialogue string    # BlenderBot expects previous dialogue as a single string    dialogue = " ".join(conversation_history)    inputs = tokenizer([dialogue], return_tensors="pt")    # Generate model response    result = model.generate(**inputs)    # Decode and print response    bot_reply = tokenizer.decode(result[0], skip_special_tokens=True)    print(bot_reply)    # Add the bot reply to the history    conversation_history.append(f"Bot: {bot_reply}")